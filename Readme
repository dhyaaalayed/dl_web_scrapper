Readme:




Time plane:

	Started:
		11.08.2022
	Now:
		18.08.200

	Achievments over Days:


		17.08.2020
			Store in jsons
		18.08.2020
			Read from jsons

	Number of days

		Using Selinum for the first time
			Research how to use it
			because of telekom animation

			Explain why


How to use:
	python load_from_web.py
		1- Generate the json files and overwrite them if they are existed
		2- Generate ansprech_partner files and overwrite them if they are existed
		3- For Montage_liste and Master_liste, Compare and add the new addresses :)

	python load_from_json.py
		1- Load the data from json
		2- Generate ansprech_partner files and overwrite them if they are existed
		3- For Montage_liste and Master_liste, Compare and add the new addresses :)


	python update_from_web.py
		1- Load the json files into classes
		2- Get the information from the web in parallel classes
		3- Update the excel files according to the new changes
		4- 


ATTENTION: If telekom changed their web elements ids, then the Navigator will not work.


______________________________
Currently:
	1- Load current stored data
	2- Update excel files of Montage liste / Master liste! and also generate new generated_ansprech_partner excel files!






Later:
	1- Load current stored data in classes
	2- Scrap new Telekom data in parallel classes
	3- Compare
	4- Take action regarding the new data:
		1- Load it to the excel files
		2- Notify our employees by sending emails :)

___________________




TODO:
	/1- Fix Navigator to get the completed address with the charachter
	/2- Fix City to get all kls, even if they have different ids
		/1- rename city_nvt_dict to nvt_list and make it list
    /3- kls class:
        /1- key must be in it not in address
            /1- Change the class
            /2- Change the navigator to modify that
            /3- And also other classes!
    /4- Address
        /Move the kls id to kls class
        /1- Add new attribute: House_char
        /2- Modify the navigator to get it
        /3- Set it empty string instead of null ig it's not existed
    5- Check out exporting json of each class/ subclass
        str function!
        city
            /nvt
                /kls
                    address
                    person
                    owner

    6- Try pickling the classes!?
        No
        Run the etl
            Just see what is the correct way to jsonify

Later:
    1- Complete the updating MontageList code
        1- Continue previous example
        2- Create updater main or a different class name!



13.09.2022
	
	I created creation_time attribute to each nvt json file
	Next: I need to load the creation time before scrapping the nvt
		if the creation time occured less than 2 hours ago
			then do not scrap!




14.09.2022
	
	Solving microsoft graph problem:


Left menu --> authentication

then

	Supported account types
	Who can use this application or access this API?
	Accounts in any organizational directory (Any Azure AD directory - Multitenant)

I changed it to this option

then I have got another error:
	AADSTS500113: No reply address is registered for the application.

I solved by:
Left menu --> authentication

then Add platform -> then web
then entering this redirect url: http://localhost:1234



19.09.2022
	
	By adding any new Baupläne folder
		Baupläne word must be replace with this: Baupläne
			because they are not the same!
				according to microsoft graph!




23.09.2022
	TODO:
		1- Implement all todo steps in json_main
		2- Test the copying and creating new folders on graph functions




Last step: Updating and uploading montageliste for 2 nvt examples

Next step: Doing that by deleting [:1] in the city.py file

ATTENTION: Update my email signature!!!!

Ask Hakan, Goerkem about overwriting current masterliste!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Later: 
	1- Run updating telekom jsons in infinity loop
		1- Require repearing the nvt instead of stopping
			By throwing timeout exception!

	2- Put mg_json_main on another service and run it at 00:00
		Using apache airflow or just using normal script :)



run certain container in background examples:

	docker-compose up -d web_scrapper_navigator
	docker-compose up -d excel_updater

to get logs:
	docker-compose logs <name of service>
	example:
	docker-compose logs excel_updater
	sudo docker-compose logs -t --tail 100 excel_updater
	sudo docker-compose logs -t --tail 100 web_scrapper
	-t # to show the timestamp

get running containers:

	docker compose ps

________________________________________________________
04.10.2022

ast.literal_eval(json_string_obj) vs json.loads

both functions convert string to python dict
, but ast.literal_eval does not work if we have non string values like boolean.

Therefore, user json.loads insread!

I discovered this problem when I added a boolean variable to store if the exploration protocol has been downloaded before or not, then this problem happend with this boolean value!





_________________________________________________________


Current TODO:
	/1- Add the template to Pulsnitz of no gpgs (Dilara)
		check out the NVT that she said

	/1.X- Check out the two addresses that Dilara mentioned

	2- Check out why uploading masterliste is not working!
		Maybe the ids are wrong?!

	/3- Check out this error: Bautzen_Masterliste

	    df["unique_id"] = df["NVT"] + "_" + df["PLZ"].apply(int).apply(str) + "_" + df["Ort"] + "_" + df["Straße"] + "_" + df["Hausnr."].apply(str) + "_" + df["Hauschar"]

	TypeError: can only concatenate str (not "int") to str






TODO Later:
	
	IF there is no gbgs of an NVT
		Copy the new template there
		Also add all telekom list of nein...



List of what I did during Hakan vocation:

	1- Fixing not saving HK Montage and VKZ Anbindung
	2- Implement saving Telekom Kommentar and Montage Kommentar in the Masterlist
	3- Microsoft Graph functionality [10 days]
		create folder
		copy file
		...
	4- Auskundigung Protokol

	5- Uploading large files problem > 4 mb
		requires openning a session at Microsoft Graph and closing it






Hakan Notes  13.10

	Email: send it imidiatly once a change happens
		Add Hakan mail



We need to install xlrd dependency for pandas to read xls excel!
	This file has all installed nvts

	fold_id is not unique at all!!!!!!!!!!



__________________________________________
To tell in the meeting:
	fold_id is not unique
		999 from 1300!!!!!!!!

	that's why I created unique id myself



_______________________________________


Current Problems:
	
	1- Uploading masterliste sometimes does not work and that proved!
		Solved, because files were oppened

	2- Apache airflow for web main, because it stops because of chrome crushing

	3- Create notification class and integrate it with the email

	4- Rebuild docker images on the cloud and rerun the code

	5- Figure out the messing address of the 18 installed



Steps:
	/1- Add uploading conditions


	/2- Delete BAU folder by finishing one of the main
		/To start the new one on a clean...

	3- Test sending emails:
		new addresses
		new changes
		upload failed

	4- Rebuild the docker images and rerun the code

	

	5- Add Airflow and make it visable in our cloud


_________________

Airflow Documentation
# installation

export AIRFLOW_HOME=~/airflow # we can choose another path
pip install apache-airflow
airflow db init

# To run server: but this command does not show dags
   airflow webserver -p 8080 

# better to use
	airflow standalone



# Create a new user admin and password admin:
airflow users  create --role Admin --username admin --email admin --firstname admin --lastname admin --password admin

No need for a config file until now :)

# Create apache py file to define a dag and a task

see this link: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Apache%20Airflow/Build%20a%20DAG%20using%20Airflow/Build%20a%20DAG%20using%20Airflow.md.html

# Submit the created dag to Airflow home folder:
 cp airflow_file_name.py $AIRFLOW_HOME/dags
 




#### For docker later
export AIRFLOW_HOME=~/airflow
cp airflow_manager.py AIRFLOW_HOME/dags

# installation steps + creating user

airflow standalone




To open a bash in a RUNNING container:
docker exec -ti <container name> /bin/bash



________________________________________________
nohup is more correct than disown, because it shows the process with S state, unlike disown that shows it with T state

sudo nohup bash excel_docker_trigger.sh &


And for web main
sudo nohup bash web_docker_trigger.sh &


then we check if a the docker container is working by calling the tail of the container
	once we see the time minutes of the last logs is the same of the current minute on our device, then the container is working fine :)

Another method to check, by checking out the date of the uploaded json files in the automated_data folders :)



DO NOT USE THIS:
What I though firstly but that was wrong!!!!
	sudo bash web_docker_trigger.sh &
	then run: disown

DO NOT USE THIS:
	However, it worked without disown with:
	sudo bash excel_docker_trigger.sh &
	!!!!!!!!!!!!!!!!!!!!!!!!!


Schluss Aufmaß

________________________________________________
GOLD: to list all running bash scripts:

	ps aux | grep bash


PROCESS STATE CODES
       Here are the different values that the s, stat and state output specifiers (header "STAT" or "S") will display to describe the state of a process:
       D    uninterruptible sleep (usually IO)
       R    running or runnable (on run queue)
       S    interruptible sleep (waiting for an event to complete)
       T    stopped, either by a job control signal or because it is being traced.
       W    paging (not valid since the 2.6.xx kernel)
       X    dead (should never be seen)
       Z    defunct ("zombie") process, terminated but not reaped by its parent.

       For BSD formats and when the stat keyword is used, additional characters may be displayed:
       <    high-priority (not nice to other users)
       N    low-priority (nice to other users)
       L    has pages locked into memory (for real-time and custom IO)
       s    is a session leader
       l    is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)
       +    is in the foreground process group.



______________________
to kill a process

the signals

	SIGUP (1) – The controlling terminal is hung up or the controlling process is dead. In such a situation, SIGUP will reload the configuration files and open/close log files.
	SIGKILL (9) – It’s a direct kill signal to the target process. It should be used as the last resort to terminate a process. If a process is terminated using SIGKILL, then it won’t save data or cleaning upon the termination of the process.
	SIGTERM (15) – It sends a termination signal to the target process. SIGTERM is the default signal to send. It’s also considered the safest method of terminating a process.



kill -<signal_number> <PID>

kill -9 the_id_of_excel_trigger_for_example




______________________
ATTENTION
	navigator.browser.set_window_size function is important to view the page in a big screen view in order not to make the page colapse the items in tablet or laptop modes!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

______________________
Steps to add a new bvh project:
	1- Add it to config.json
		This more than enouph for web_main to get the json files

	telekom_addresses phase:
		1- Get the telekom_list file and put it in:
			bvh_name/Baupläne (HK+NVT)/telekom_list/telekom_addresses.csv
		2- Run mg_json_main after setting EXPORT_TELEKOM_ADDRESSES = True
			but this works only for one bvh at a time 




FINALLY To see logs on docker :)
	python -u file.py




________________________________________________
New Requirements:



1- For bulk address
	1- Set the status to be complete gfap...
	2- Get it's fold and kls ids
	3- Add it also to ansprechpartnerlist




_______________________________________________
To update my ssh keys for github authantication:
Run:
	ssh-keygen -R github.com



_________________________________________________
I changed the download folder of the telekom addresses from:
download_folder = Path(bvh_root_path) / "telekom_list"
to:
download_folder = Path(bvh_root_path) / "Baupläne (HK+NVT)" / "telekom_list"
because the was the true path of Prignitz
need to check for other BVHs as well!

























